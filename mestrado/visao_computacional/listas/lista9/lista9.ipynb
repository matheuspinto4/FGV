{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f52afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d55e98f",
   "metadata": {},
   "source": [
    "# **Questão 1. Implementação da Câmera Lenta.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8821844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vídeo de entrada: onca.mp4, FPS: 29.97002997002997, Dimensões: 1280x720\n"
     ]
    }
   ],
   "source": [
    "video_path = 'onca.mp4' \n",
    "fator = 8 \n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Erro: Não foi possível abrir o vídeo em {video_path}\")\n",
    "    exit()\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(f\"Vídeo de entrada: {video_path}, FPS: {fps}, Dimensões: {width}x{height}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec88c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "outrep_width = width\n",
    "outrep_height = height\n",
    "\n",
    "outlin_width = width\n",
    "outlin_height = height\n",
    "\n",
    "outopt_width = width\n",
    "outopt_height = height\n",
    "\n",
    "outcomb_width = 3 * width \n",
    "outcomb_height = height\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "outrep_path = 'imagens\\\\out_rep.mp4'\n",
    "outlin_path = 'imagens\\\\out_lin.mp4'\n",
    "outopt_path = 'imagens\\\\out_opt.mp4'\n",
    "outcomb_path = 'imagens\\\\out_comb.mp4'\n",
    "\n",
    "outrep = cv2.VideoWriter(outrep_path, fourcc, fps * fator, (outrep_width, outrep_height))\n",
    "outlin = cv2.VideoWriter(outlin_path, fourcc, fps * fator, (outlin_width, outlin_height))\n",
    "outopt = cv2.VideoWriter(outopt_path, fourcc, fps * fator, (outopt_width, outopt_height))\n",
    "outcomb = cv2.VideoWriter(outcomb_path, fourcc, fps * fator, (outcomb_width, outcomb_height))\n",
    "\n",
    "if not all([outrep.isOpened(), outlin.isOpened(), outopt.isOpened(), outcomb.isOpened()]):\n",
    "    print(\"Erro: Não foi possível abrir um ou mais arquivos de saída para escrita.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc8028",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def combinar_frames(frames_list):\n",
    "    \"\"\"\n",
    "    Combina uma lista de frames (cada um sendo uma lista de um único frame) horizontalmente.\n",
    "    Ex: [[frame1], [frame2], [frame3]] -> [frame1 | frame2 | frame3]\n",
    "    \"\"\"\n",
    "    if not frames_list:\n",
    "        return None\n",
    "    \n",
    "    height, width, channels = frames_list[0][0].shape\n",
    "    \n",
    "    combined_frame = np.zeros((height, width * len(frames_list), channels), dtype=np.uint8)\n",
    "\n",
    "    for i, frame_wrapper in enumerate(frames_list):\n",
    "        combined_frame[:, i * width : (i + 1) * width, :] = frame_wrapper[0]\n",
    "\n",
    "    return combined_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coord_x, coord_y = np.meshgrid(np.arange(width), np.arange(height))\n",
    "\n",
    "cont_frames = 0\n",
    "total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "bloco = int(total_frames / 10) if total_frames > 10 else 1\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print(\"Erro: Não foi possível ler o primeiro frame do vídeo.\")\n",
    "    cap.release()\n",
    "    outrep.release()\n",
    "    outlin.release()\n",
    "    outopt.release()\n",
    "    outcomb.release()\n",
    "    exit()\n",
    "\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando:  10 %\n",
      "Processando:  20 %\n",
      "Processando:  30 %\n",
      "Processando:  40 %\n",
      "Processando:  50 %\n",
      "Processando:  60 %\n",
      "Processando:  70 %\n",
      "Processando:  80 %\n",
      "Processando:  90 %\n",
      "Processando:  100 %\n",
      "Processamento concluído. Liberando recursos.\n",
      "Vídeos de saída salvos.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    cont_frames += 1\n",
    "\n",
    "    if cont_frames % bloco == 0:\n",
    "        print('Processando: ', int(cont_frames / bloco) * 10, '%')\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break \n",
    "\n",
    "    frame_repeat_orig = cv2.resize(prev_frame, (outrep_width, outrep_height))\n",
    "    frame_linear_orig = cv2.resize(prev_frame, (outlin_width, outlin_height))\n",
    "    frame_optflow_orig = cv2.resize(prev_frame, (outopt_width, outopt_height))\n",
    "\n",
    "    frame_combinado_orig = combinar_frames([[frame_repeat_orig], [frame_linear_orig], [frame_optflow_orig]])\n",
    "\n",
    "    outrep.write(frame_repeat_orig)\n",
    "    outlin.write(frame_linear_orig)\n",
    "    outopt.write(frame_optflow_orig)\n",
    "    outcomb.write(frame_combinado_orig)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    for i in range(1, fator):\n",
    "        frame_repeat = prev_frame\n",
    "\n",
    "        frame_linear = cv2.addWeighted(prev_frame, (fator - i) / fator, frame, i / fator, 0)\n",
    "\n",
    "        map_x = coord_x + (flow[:,:,0] * i / fator)\n",
    "        map_y = coord_y + (flow[:,:,1] * i / fator)\n",
    "        \n",
    "        frame_optflow_warped = cv2.remap(prev_frame, map_x.astype(np.float32), map_y.astype(np.float32), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        peso_fluxo_otico = (fator - i) / fator\n",
    "        peso_proximo_frame = i / fator\n",
    "        frame_optflow = cv2.addWeighted(frame_optflow_warped, peso_fluxo_otico, frame, peso_proximo_frame, 0)\n",
    "\n",
    "        frame_combinado = combinar_frames([[frame_repeat], [frame_linear], [frame_optflow]])\n",
    "        \n",
    "        outrep.write(frame_repeat)\n",
    "        outlin.write(frame_linear)\n",
    "        outopt.write(frame_optflow)\n",
    "        outcomb.write(frame_combinado)\n",
    "\n",
    "    prev_frame = frame\n",
    "    prev_gray = gray\n",
    "\n",
    "print(\"Processamento concluído. Liberando recursos.\")\n",
    "cap.release()\n",
    "outrep.release()\n",
    "outlin.release()\n",
    "outopt.release()\n",
    "outcomb.release()\n",
    "print(\"Vídeos de saída salvos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2aa6eb",
   "metadata": {},
   "source": [
    "# **Questão 2. Comentários.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8188c1",
   "metadata": {},
   "source": [
    "- Para os três métodos de interpolação a onça parece se mexer abruptamente dependendo do tempo de vídeo.\n",
    "- Estes tempos são os momentos em que há uma diferença muito abrupta entre os frames, ou seja, os momentos em qu eela se mexe muito rapidamente.\n",
    "- Porém, vale ressaltar que os resultados foram satisfatórios. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".FGV_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
