# **Image Processing**

## **Point Operators**
The simplest kinds of image processing transforms.

Examples of such operators:
- Brightness;
- Contrast adjustments; &
- Color correction and transformations.

### **Pixel transforms**

A general image processing operator is a function that takes one or more input images and produces an output image.

$$
g(x) = h(f(x)) 
$$

For discrete (sampled) images, the domain consists of a finite number of pixel locations, $ x = (i,j)$ :

$$
g(i,j) = h(f(i,j))
$$

Two commonly used point processes are multiplication and addition with a constant.

$$
g(x) = af(x) + b(x)
$$

The parameters $a > 0$ and $b$ are often called the gain and bias parameters; sometimes these parameters are said to control *contrast* and *brightness*, respectively. The bias and gain parameters can also be spatially varying,

$$
g(x) = a(x)f(x) + b(x)
$$

Multiplicative gain is a linear operation, as it obeys the superposition principle,

$$
h(f_0 + f_1) = h(f_0) + h(f_1)
$$

Another commonly used two-input operator is the *linear blend* operator,

$$
g(x) = (1 - \alpha)f_0(x) + \alpha f_1(x)
$$

By varying $\alpha$ from $0 \rightarrow 1$, this operator can be used to perform a temporal *cross-dissolve* between two images or videos.

One non-linear transform is *gamma correction*. To invert the gamma mapping applied by the sensor, we can use

$$
g(x) = [f(x)]^{\frac{1}{\gamma}}
$$

where a gamma value of $\gamma \approx 2.2$ is reasonable fit for most digital cameras.

### **Color transforms**

It usually makes sense to think about them as highly correlated signals with strong connections to the image formation process.

Chromaticity coordinates or even simples color ratios can first be computed and then used after manipulating the luminance $Y$ to re-compute a valid RBG image with the same hue and saturation.

### **Compositing and matting**

- Matting: The provess of extracting the object from the original image.
- Compositing: Inseting it into another image (without visible artifacts).

The intermediate representation used for the foreground object between these two stages is called an *alpha-matted color image*. Pixels within the object are fully opaque ($\alpha = 1$), while pixels fully outside the object are transparent($\alpha = 0$). 

### **Histogram equalization**

The ideia is to normalize the histogram of the rgb channels of an image. We create the map 

$$
c(I) = \frac{1}{N} \sum_{i=0}^{I}{h(i)} = c(I - 1) + \frac{1}{N}h(I)
$$

For any given intensity, we can look up its corresponding percentile $c(I)$ and determine the final value that the pixel should take.

We can compose the original and equalized images:

$$
f(I) = \alpha c(I) + (1 - \alpha)I 
$$

#### **Locally adaptive equalization**

While global histogram equalization can be useful, for some images it might be preferable to aaply different kinds of equalization in different regions.
We can recompute the histogram for every $M$ x $M$ moving block centered at each pixel. 

A more efficient approach is to compute non-overlapped block-based equalization functions as before, but to then smoothly interpolate the transfer functions as we move between blocks. This technic is know as *adaptative histogram equalization* (AHE)

$$
f_{s,t}{I} = (1 - s)(1-t)f_{00}{I} + s(1-t)f_{10}{I} + (1 - s)tf_{01}{I} + stf_{11}{I}
$$

## **Linear filtering**

The most widely used type of neighborhood operator ia a linear filter, where an output pixel's value is a weighted sum of pixel values withing a small neighborhood $N$.

$g(i, j) = \sum_{k,l}{f(i + k, j + l)h(k, l)}$

or

$$
g = f \otimes h
$$

A common variant on this formula is 

$$
g(i,j) = \sum_{k,l}{f(i - k, j - l)h(k,l)} = \sum_{k,l}{f(k, l)h(i-k,j-l)}
$$

where the sign of the offsets in $f$ has been reversed. This is called the *convolution* operator 

$$
g = f * h
$$

We can write down has a matrix-vector multiplication:

$$
g = Hf
$$

where the (sparse) H matrix contains the convolution kernels.

### **Seperable filtering**

If the convolution kernel is a matrix, then the process of performing a convolution requires $K^2$ operations per pixel, where $K$ is the size (width or height) of the convolution kernel. In many cases, this operation can be significantly sped up by first performing a one-dimensional horizontal convolution followed by a one-dimensional vertical convolution, which requires a total of 2K operations per pixel.